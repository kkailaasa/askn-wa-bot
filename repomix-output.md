This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-12 20:38:15

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
.env.example
app
  db
    database.py
    models.py
  scheduler
    tasks.py
    __init__.py
  tasks
    utils.py
    __init__.py
  utils
    logging_config.py
    __init__.py
  __init__.py
docker-compose.yml
Dockerfile
main.py
README.md
requirements.txt
__init__.py
```

# Repository Files


## .env.example

- Characters: 406
- Tokens: 130

```text
DIFY_BASE_URL=http://your-dify-instance/v1
DIFY_KEY=your-dify-key

TWILIO_ACCOUNT_SID=your-twilio-sid
TWILIO_AUTH_TOKEN=your-twilio-token
TWILIO_NUMBER=your-twilio-number

RATE_LIMIT=3
TIME_WINDOW=60

NOCODB_BASE_URL=http://noco:8080
NOCODB_API_TOKEN=your-nocodb-token
NOCODB_TABLE_ID=mztyqcjfbbijx16

# Logging configuration
ENVIRONMENT=development # or production
LOG_LEVEL=DEBUG # or INFO for production
```

## docker-compose.yml

- Characters: 1592
- Tokens: 464

```yaml
version: '3.8'
services:
  web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: an_wa_bot
    ports:
      - "8051:8000"
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DIFY_BASE_URL=${DIFY_BASE_URL}
      - DIFY_KEY=${DIFY_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_NUMBER=${TWILIO_NUMBER}
    depends_on:
      - redis
      - celery_worker
    volumes:
      - ./app_data:/app/app_data
    networks:
      - internal
      - dify_network
    restart: unless-stopped

  redis:
    image: redis:6.2-alpine
    container_name: an_wa_redis
    volumes:
      - ./redis_data:/data
    command: ["redis-server", "--bind", "0.0.0.0", "--protected-mode", "no"]
    networks:
      - internal
    restart: unless-stopped

  celery_worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: an_wa_celery_worker
    command: celery -A app.scheduler.tasks worker --loglevel=info
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - DIFY_BASE_URL=${DIFY_BASE_URL}
      - DIFY_KEY=${DIFY_KEY}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_NUMBER=${TWILIO_NUMBER}
    depends_on:
      - redis
    volumes:
      - ./app_data:/app/app_data
    networks:
      - internal
      - dify_network
    restart: unless-stopped

networks:
  internal:
    driver: bridge
  dify_network:
    external: true
    name: dify-chandra_default

volumes:
  app_data:
  redis_data:
```

## Dockerfile

- Characters: 735
- Tokens: 197

```text
# Dockerfile
FROM python:3.10-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first to leverage Docker cache
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code
COPY . .

# Create directory for SQLite database and logs
RUN mkdir -p /app/app_data && \
    chmod 777 /app/app_data

# Add the current directory to PYTHONPATH
ENV PYTHONPATH=/app:${PYTHONPATH}

# Set environment variables
ENV PYTHONUNBUFFERED=1

# Default command
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## main.py

- Characters: 5912
- Tokens: 1157

```python
from fastapi import FastAPI, Form, HTTPException, Request
from typing import Optional
from app.scheduler.tasks import process_question
from app.db.database import init_db
from app.utils.logging_config import setup_logging
import logging
from datetime import datetime

# Configure logging with timestamp
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app_data/app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


app = FastAPI(title="WhatsApp Bot API")

@app.on_event("startup")
async def startup_event():
    try:
        init_db()
        logger.info("Database initialized successfully")
    except Exception as e:
        logger.error(f"Failed to initialize database: {str(e)}")
        raise

@app.get("/")
async def root():
    return {
        "status": "running",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@app.post("/message")
async def reply(request: Request):
    try:
        # Get form data
        form = await request.form()

        # Log all incoming data for debugging
        logger.info("Received webhook data:")
        for key, value in form.items():
            logger.info(f"{key}: {value}")

        # Extract fields with defaults
        message_sid = form.get('MessageSid', '')
        body = form.get('Body', '')
        from_number = form.get('From', '')
        to_number = form.get('To', '')
        num_media = form.get('NumMedia', '0')
        message_status = form.get('MessageStatus', '')
        sms_status = form.get('SmsStatus', '')
        message_type = form.get('MessageType', '')

        # Log basic request info
        logger.info(f"Received webhook - MessageSid: {message_sid}, From: {from_number}, To: {to_number}")

        # Handle status updates - only for specific status types
        if message_status in ['sent', 'delivered', 'read', 'failed'] or sms_status in ['sent', 'delivered', 'read', 'failed']:
            status = message_status or sms_status
            logger.info(f"Status update received: {status}")
            return {
                "status": "success",
                "type": "status_update",
                "message": f"Status update ({status}) received"
            }

        # Process incoming messages
        if message_type == 'text' or body or int(num_media) > 0:
            # Validate From number
            if not from_number:
                logger.error("Missing From number")
                return {
                    "status": "error",
                    "message": "Missing From number"
                }

            # Clean the phone number
            from_number = from_number.strip()
            if not from_number.startswith("whatsapp:"):
                from_number = f"whatsapp:{from_number}"

            # Handle media messages
            media_items = []
            if num_media and int(num_media) > 0:
                num_media_int = int(num_media)
                logger.info(f"Media message received - Count: {num_media_int}")

                # Collect all media URLs and types
                for i in range(num_media_int):
                    url = form.get(f'MediaUrl{i}')
                    content_type = form.get(f'MediaContentType{i}')

                    if url and content_type:
                        media_items.append({
                            "url": url,
                            "content_type": content_type,
                            "index": i
                        })
                        logger.info(f"Media {i}: Type: {content_type}, URL: {url}")

                message_text = body if body else "Image message"
                try:
                    process_question.delay(message_text, from_number, media_items)
                    logger.info(f"Task queued successfully for {from_number} with {len(media_items)} media items")
                    return {
                        "status": "success",
                        "message": "Message with media received and queued for processing"
                    }
                except Exception as e:
                    logger.error(f"Failed to queue media task: {str(e)}")
                    raise HTTPException(
                        status_code=500,
                        detail="Failed to process media message"
                    )

            # Handle text-only messages
            elif body:
                logger.info(f"Processing text message - From: {from_number}, Body: {body}")

                try:
                    process_question.delay(body, from_number)
                    logger.info(f"Task queued successfully for {from_number}")
                    return {
                        "status": "success",
                        "message": "Message received and queued for processing"
                    }
                except Exception as e:
                    logger.error(f"Failed to queue task: {str(e)}")
                    raise HTTPException(
                        status_code=500,
                        detail="Failed to process message"
                    )

        # Handle other types of webhooks
        logger.warning("Received webhook with no message content")
        return {
            "status": "success",
            "type": "unknown",
            "message": "Webhook received but no message content found"
        }

    except Exception as e:
        logger.error(f"Unexpected error processing webhook: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail="Internal server error"
        )

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat()
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

## README.md

- Characters: 1300
- Tokens: 322

````markdown
# prerequisites
- python3
- git
- redis
- tmux

Redis-server is used for caching the user login, conversation id, and rate limiting. It is also used by celery as broker.

# commands to run
commands need to run from the project_root_folder
- after cloning the progect create a python venv
- then install all the libraries from requirements.txt
- then run the uvicorn command `uvicorn main:app --host 0.0.0.0 --port 8000`
to run it in detached mode you can use nohup at the begining of the command and & at the end
- then run the celery command `celery -A scheduler.tasks worker --loglevel=info`
to run this in detached mode you can use nohup at the begining of the command and & at the end

## Deploying with Docker

Follow these steps to deploy the application using Docker:

0. Clone the Git repository:
    ```bash
    git clone <repository-url>
    ```

1. Update your `.env` file with the necessary environment variables.

2. Build the Docker image:
    ```bash
    docker build -t an-wa-bot:v1 .
    ```

3. Run Docker Compose:
    ```bash
    docker compose up -d
    ```

4. Check the logs to ensure everything is running correctly:
    ```bash
    docker compose logs -f
    ```

5. Configure your reverse proxy according to your setup.

6. Configure Cloudflare as needed for your deployment.
````

## requirements.txt

- Characters: 113
- Tokens: 34

```text
fastapi
uvicorn
twilio
python-decouple
python-multipart
dify-client
redis
celery
sqlalchemy
requests
python-magic
```

## __init__.py

- Characters: 0
- Tokens: 0

```python

```

## app\__init__.py

- Characters: 0
- Tokens: 0

```python

```

## app\db\database.py

- Characters: 446
- Tokens: 103

```python
# database.py
import os
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.db.models import Base
from decouple import config

# Get the absolute path to the app_data directory
BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DB_PATH = os.path.join(BASE_DIR, 'app_data', 'chat.db')
os.makedirs(os.path.dirname(DB_PATH), exist_ok=True)

DATABASE_URL = f"sqlite:///{DB_PATH}"
```

## app\db\models.py

- Characters: 507
- Tokens: 114

```python
# models.py
from sqlalchemy import Column, Integer, String, DateTime, Text
from sqlalchemy.ext.declarative import declarative_base
from datetime import datetime

Base = declarative_base()

class MessageLog(Base):
    __tablename__ = 'message_logs'

    id = Column(Integer, primary_key=True)
    phone_number = Column(String(50))
    message = Column(Text)
    response = Column(Text)
    created_at = Column(DateTime, default=datetime.utcnow)
    status = Column(String(50))  # success, error, rate_limited
```

## app\scheduler\tasks.py

- Characters: 15532
- Tokens: 3172

```python
# tasks.py
from celery import Celery
from dify_client import ChatClient
from decouple import config
from app.tasks.utils import (
    send_message,
    logger,
    is_rate_limited,
    log_message,
    download_media_from_twilio,
    download_image_as_base64
)
import requests
from typing import Optional, List, Dict
import tempfile
import os
import time
from twilio.rest import Client
import re
import json

app = Celery('tasks', broker='redis://redis:6379/0', backend='redis://redis:6379/0')
app.conf.update(
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',
    timezone='UTC',
    enable_utc=True,
)

# Initialize Twilio client
account_sid = config('TWILIO_ACCOUNT_SID')
auth_token = config('TWILIO_AUTH_TOKEN')
twilio_client = Client(account_sid, auth_token)

def get_active_conversation(base_url: str, dify_key: str, dify_user: str) -> Optional[str]:
    """
    Get the conversation ID if there's an active conversation less than 1 hour old

    Args:
        base_url: Dify API base URL
        dify_key: Dify API key
        dify_user: User identifier

    Returns:
        str: Conversation ID if found and active, None otherwise
    """
    try:
        # Get most recent conversation
        conversations_response = requests.get(
            f"{base_url}/conversations",
            headers={'Authorization': f'Bearer {dify_key}'},
            params={
                'user': dify_user,
                'limit': 1,  # We only need the most recent one
                'sort_by': '-updated_at'  # Most recent first
            }
        )
        conversations_response.raise_for_status()
        conversations_data = conversations_response.json()

        if not conversations_data.get("data"):
            return None

        latest_conversation = conversations_data["data"][0]
        updated_at = latest_conversation.get("updated_at", 0)

        # Check if conversation is less than 1 hour old
        current_time = int(time.time())
        one_hour = 3600  # seconds

        if (current_time - updated_at) < one_hour:
            return latest_conversation.get("id")

        return None

    except Exception as e:
        logger.error(f"Error getting conversation: {str(e)}")
        return None

def process_dify_response(response_text: str) -> Optional[dict]:
    """
    Process Dify response to extract message content and other relevant data

    Args:
        response_text: Raw SSE response text from Dify

    Returns:
        dict containing:
            - text: The main message content (from message or thought)
            - urls: List of image/media URLs
            - error: Any error message (if present)
    """
    try:
        # Split the response into individual SSE events
        events = response_text.strip().split('\n\n')
        result = {
            'text': '',
            'urls': [],
            'error': None
        }

        for event in events:
            if not event.startswith('data: '):
                continue

            try:
                data = json.loads(event[6:])  # Remove 'data: ' prefix

                # Extract regular message content
                if data.get('event') == 'message' or data.get('event') == 'agent_message':
                    answer = data.get('answer', '')
                    if answer:
                        # Append to existing text if we're getting streamed tokens
                        if result['text']:
                            result['text'] += answer
                        else:
                            result['text'] = answer

                # Extract thought content (which may contain the final response)
                elif data.get('event') == 'agent_thought':
                    thought = data.get('thought', '')
                    if thought:
                        # Replace existing text if this is a thought
                        # as thoughts typically contain the complete response
                        result['text'] = thought

                # Extract node output that might contain image URLs
                elif data.get('event') == 'node_finished':
                    node_data = data.get('data', {})
                    outputs = node_data.get('outputs', {})

                    # Check for errors in outputs
                    if outputs.get('status_code') == 400:
                        error_body = outputs.get('body', '')
                        if error_body:
                            try:
                                error_data = json.loads(error_body)
                                result['error'] = error_data.get('detail')
                            except json.JSONDecodeError:
                                result['error'] = error_body

                    # Check for files/media in outputs
                    files = outputs.get('files', [])
                    if files and isinstance(files, list):
                        for file in files:
                            if file.get('type') == 'image' and file.get('url'):
                                result['urls'].append(file['url'])

                # Check for workflow completion
                elif data.get('event') == 'workflow_finished':
                    workflow_data = data.get('data', {})
                    outputs = workflow_data.get('outputs', {})
                    if outputs.get('answer'):
                        result['text'] = outputs['answer']

            except json.JSONDecodeError:
                continue

        # Process URLs in the final text content
        if result['text']:
            # First, find URLs in markdown-style links [text](url)
            markdown_pattern = r'\[([^\]]+)\]\((https?://[^)]+)\)'
            markdown_urls = re.findall(markdown_pattern, result['text'])

            # Extract URLs from markdown links
            for text, url in markdown_urls:
                if (any(img_ext in url.lower() for img_ext in ['.png', '.jpg', '.jpeg', '.gif']) or
                    'cloudflarestorage.com' in url):
                    if url not in result['urls']:
                        result['urls'].append(url)
                    # Replace the entire markdown link with just the text
                    result['text'] = result['text'].replace(f'[{text}]({url})', text)

            # Then find any remaining plain URLs, excluding trailing punctuation
            url_pattern = r'https?://[^\s<"]+?(?=[.!?,;]?\s|$)'
            plain_urls = re.findall(url_pattern, result['text'])

            for url in plain_urls:
                # Check if URL is an image or Cloudflare storage URL
                if (any(img_ext in url.lower() for img_ext in ['.png', '.jpg', '.jpeg', '.gif']) or
                    'cloudflarestorage.com' in url):
                    if url not in result['urls']:
                        result['urls'].append(url)
                    # Remove the URL from the text, being careful with punctuation
                    # First try to find and remove "url." pattern
                    if url + '.' in result['text']:
                        result['text'] = result['text'].replace(url + '.', '')
                    # Then try removing just the url if the first replacement didn't work
                    else:
                        result['text'] = result['text'].replace(url, '')
                    result['text'] = result['text'].strip()

        # Clean up text content
        result['text'] = ' '.join(result['text'].split())
        return result

    except Exception as e:
        logger.error(f"Error processing Dify response: {str(e)}")
        return None

def get_dify_base_url():
    """Get base URL without trailing slash"""
    base_url = config('DIFY_BASE_URL').rstrip('/')
    if not base_url.endswith('/v1'):
        base_url = f"{base_url}/v1"
    return base_url

def upload_file_to_nocodb(media_content: bytes, content_type: str, phone_number: str) -> Optional[Dict]:
    """Upload a file to NocoDB and return the signed URL"""
    try:
        base_url = config('NOCODB_BASE_URL').rstrip('/')
        api_token = config('NOCODB_API_TOKEN')
        table_id = config('NOCODB_TABLE_ID')

        # First, upload the file to NocoDB storage
        upload_url = f"{base_url}/api/v2/storage/upload"

        # Create a temporary file
        extension = '.jpg' if 'jpeg' in content_type else '.' + content_type.split('/')[-1]
        with tempfile.NamedTemporaryFile(suffix=extension, delete=False) as temp_file:
            temp_file.write(media_content)
            temp_file_path = temp_file.name

        try:
            # Upload the file
            files = {
                'file': (f'image{extension}', open(temp_file_path, 'rb'), content_type)
            }
            headers = {
                'xc-token': api_token
            }

            logger.info(f"Uploading file to NocoDB storage: {upload_url}")
            upload_response = requests.post(
                upload_url,
                headers=headers,
                files=files
            )
            upload_response.raise_for_status()

            file_data = upload_response.json()
            logger.info(f"File upload response: {file_data}")

            if not file_data or not isinstance(file_data, list) or not file_data[0].get('url'):
                raise ValueError("Invalid upload response format")

            file_url = file_data[0]['url']

            # Now create the record with the URL
            create_url = f"{base_url}/api/v2/tables/{table_id}/records"
            record_data = {
                "phone_number": phone_number,
                "profile_photo": [{
                    "url": file_url,
                    "title": f"image_{phone_number}",
                    "mimetype": content_type,
                    "size": len(media_content)
                }]
            }

            logger.info(f"Creating record in NocoDB: {create_url}")
            record_response = requests.post(
                create_url,
                headers={'xc-token': api_token, 'Content-Type': 'application/json'},
                json=record_data
            )
            record_response.raise_for_status()
            record_data = record_response.json()

            record_id = record_data.get('Id')
            if not record_id:
                raise ValueError("No record ID in response")

            get_url = f"{base_url}/api/v2/tables/{table_id}/records/{record_id}"
            get_response = requests.get(
                get_url,
                headers={'xc-token': api_token}
            )
            get_response.raise_for_status()
            get_data = get_response.json()

            if not get_data.get('profile_photo') or not get_data['profile_photo'][0].get('signedUrl'):
                raise ValueError("No signed URL in record")

            signed_url = get_data['profile_photo'][0]['signedUrl']
            logger.info(f"Got signed URL: {signed_url}")

            return {"url": signed_url}

        finally:
            # Clean up temporary file
            os.unlink(temp_file_path)

    except Exception as e:
        logger.error(f"Error uploading file to NocoDB: {str(e)}")
        if hasattr(e, 'response'):
            logger.error(f"Upload response content: {e.response.text}")
        return None

@app.task
def process_question(Body: str, From: str, media_items: Optional[List[Dict]] = None):
    """Process incoming WhatsApp message with optional media"""
    logger.info(f"Processing message - From: {From}, Media Items: {len(media_items) if media_items else 0}")

    try:
        if is_rate_limited(From):
            logger.info(f"Rate limit exceeded for {From}")
            send_message(From, "You have exceeded the message rate limit. Please try again later.")
            return

        dify_key = config("DIFY_KEY")
        base_url = get_dify_base_url()
        chat_url = f"{base_url}/chat-messages"

        # Format user identifier
        dify_user = From if From.startswith("whatsapp:") else f"whatsapp:{From.strip()}"

        # Get active conversation if exists
        conversation_id = get_active_conversation(base_url, dify_key, dify_user)
        if conversation_id:
            logger.info(f"Using existing conversation: {conversation_id}")
        else:
            logger.info("Creating new conversation")

        # Process media if present
        uploaded_files = []
        if media_items:
            for item in media_items:
                media_content = download_media_from_twilio(item['url'])
                if media_content:
                    file_info = upload_file_to_nocodb(
                        media_content,
                        item['content_type'],
                        dify_user
                    )
                    if file_info and 'url' in file_info:
                        uploaded_files.append({
                            'type': 'image',
                            'transfer_method': 'remote_url',
                            'url': file_info['url']
                        })
                        logger.info(f"File uploaded to NocoDB with URL: {file_info['url']}")

        # Construct query
        query_parts = [f"User {dify_user}:"]
        if Body:
            query_parts.append(Body)
        if uploaded_files:
            for file_info in uploaded_files:
                if file_info.get('url'):
                    query_parts.append(f"Image URL: {file_info['url']}")

        modified_query = " ".join(query_parts)

        # Prepare message parameters
        message_params = {
            'query': modified_query,
            'user': dify_user,
            'inputs': {},
            'files': uploaded_files,
            'response_mode': "streaming",
            'conversation_id': conversation_id
        }

        logger.info(f"Sending chat message to: {chat_url}")
        logger.info(f"Message params: {message_params}")

        # Make request to Dify
        chat_response = requests.post(
            chat_url,
            headers={'Authorization': f'Bearer {dify_key}'},
            json=message_params,
            stream=True
        )
        chat_response.raise_for_status()

        # Accumulate streaming response
        full_response = ''
        for line in chat_response.iter_lines():
            if line:
                decoded_line = line.decode('utf-8')
                full_response += decoded_line + '\n\n'

        logger.info("Processing full response")
        result = process_dify_response(full_response)

        if not result:
            raise ValueError("No valid response content found in Dify response")

        if result.get('error'):
            raise ValueError(f"Error in Dify response: {result['error']}")

        # Send message with media URLs if available
        if result['urls']:
            logger.info(f"Sending message with {len(result['urls'])} media attachments")
            send_message(From, result['text'], result['urls'])
        else:
            logger.info("Sending text-only message")
            send_message(From, result['text'])

        log_message(From, Body, result['text'], "success")

    except Exception as e:
        logger.error(f"Error processing message: {str(e)}")
        if hasattr(e, 'response'):
            logger.error(f"Response content: {e.response.text}")
        log_message(From, Body, str(e), "error")
        error_msg = "Sorry, I encountered an error processing your message. Please try again later."
        send_message(From, error_msg)
```

## app\scheduler\__init__.py

- Characters: 0
- Tokens: 0

```python

```

## app\tasks\utils.py

- Characters: 5767
- Tokens: 1320

```python
# utils.py
import logging
import redis
import requests
import base64
from twilio.rest import Client
from decouple import config
from app.db.models import MessageLog
from app.db.database import SessionLocal
from typing import Optional, List, Dict, Union

# Twilio configuration
account_sid = config('TWILIO_ACCOUNT_SID')
auth_token = config('TWILIO_AUTH_TOKEN')
client = Client(account_sid, auth_token)
twilio_number = config('TWILIO_NUMBER')

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app_data/app.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def log_message(phone_number: str, message: str, response: str, status: str):
    db = SessionLocal()
    try:
        log_entry = MessageLog(
            phone_number=phone_number,
            message=message,
            response=response,
            status=status
        )
        db.add(log_entry)
        db.commit()
    except Exception as e:
        logger.error(f"Error logging message: {e}")
        db.rollback()
    finally:
        db.close()

def send_message(
    to_number: str,
    body_text: Optional[str] = None,
    media_url: Optional[Union[str, List[str]]] = None
) -> Optional[str]:
    """
    Send a WhatsApp message with optional media

    Args:
        to_number: Destination phone number
        body_text: Optional text message
        media_url: Optional media URL or list of URLs

    Returns:
        Message SID if successful, None otherwise
    """
    try:
        # Validate at least one of body or media is present
        if not body_text and not media_url:
            logger.error("Both message body and media are empty")
            return None

        # Format WhatsApp number correctly
        if not to_number.startswith("whatsapp:"):
            to_number = f"whatsapp:{to_number.strip()}"
        else:
            parts = to_number.split(":")
            to_number = f"{parts[0]}:{parts[1].strip()}"

        # Prepare message parameters
        message_params = {
            'from_': f"whatsapp:{twilio_number.strip()}",
            'to': to_number
        }

        # Add body if present
        if body_text and body_text.strip():
            message_params['body'] = body_text

        # Add media if present
        if media_url:
            if isinstance(media_url, str):
                media_url = [media_url]
            message_params['media_url'] = media_url

        # Send message
        message = client.messages.create(**message_params)

        logger.info(f"Message sent to {to_number} - SID: {message.sid}")
        log_message(
            to_number,
            f"Body: {body_text}, Media: {media_url}",
            f"Message SID: {message.sid}",
            "success"
        )
        return message.sid

    except Exception as e:
        logger.error(f"Error sending message to {to_number}: {e}")
        log_message(to_number, body_text or "", str(e), "error")
        raise e

# Redis rate limiting
redis_client = redis.StrictRedis(host='redis', port=6379)
RATE_LIMIT = config('RATE_LIMIT', default=2, cast=int)
TIME_WINDOW = config('TIME_WINDOW', default=60, cast=int)

def is_rate_limited(phone_number: str) -> bool:
    """Check if a phone number has exceeded rate limits"""
    key = f"rate_limit:{phone_number}"
    current_count = redis_client.get(key)

    if current_count is None:
        redis_client.setex(key, TIME_WINDOW, 1)
        return False
    elif int(current_count) < RATE_LIMIT:
        redis_client.incr(key)
        return False
    else:
        log_message(phone_number, "", "Rate limit exceeded", "rate_limited")
        return True

def get_mime_type(file_extension: str) -> Optional[str]:
    """Get MIME type for common WhatsApp supported formats"""
    mime_types = {
        'jpg': 'image/jpeg',
        'jpeg': 'image/jpeg',
        'png': 'image/png',
        'webp': 'image/webp',
        'pdf': 'application/pdf',
        'mp3': 'audio/mpeg',
        'mp4': 'video/mp4',
        'ogg': 'audio/ogg',
        'amr': 'audio/amr',
        'vcf': 'text/x-vcard'
    }
    return mime_types.get(file_extension.lower())

def download_media_from_twilio(media_url: str) -> Optional[bytes]:
    """
    Download media content from Twilio's media URL

    Args:
        media_url: The URL of the media to download

    Returns:
        Optional[bytes]: The media content as bytes if successful, None otherwise
    """
    try:
        # Get media content using Twilio client credentials
        response = requests.get(
            media_url,
            auth=(account_sid, auth_token),
            stream=True
        )
        response.raise_for_status()

        # Read and return the content
        return response.content

    except Exception as e:
        logger.error(f"Error downloading media from Twilio: {str(e)}")
        return None

def download_image_as_base64(url: str) -> Optional[str]:
    """Download image from URL and convert to base64 string"""
    try:
        response = requests.get(url)
        response.raise_for_status()

        # Convert to base64
        image_base64 = base64.b64encode(response.content).decode('utf-8')

        # Get file extension from URL
        extension = url.split('.')[-1].split('?')[0].lower()
        if extension in ['jpg', 'jpeg']:
            mime_type = 'image/jpeg'
        elif extension == 'png':
            mime_type = 'image/png'
        else:
            mime_type = 'image/jpeg'  # default to jpeg

        return f"data:{mime_type};base64,{image_base64}"
    except Exception as e:
        logger.error(f"Error converting image to base64: {str(e)}")
        return None
```

## app\tasks\__init__.py

- Characters: 0
- Tokens: 0

```python

```

## app\utils\logging_config.py

- Characters: 1698
- Tokens: 371

```python
import logging
import os
from decouple import config

def setup_logging():
    # Get environment variables
    environment = config('ENVIRONMENT', default='production')
    log_level = config('LOG_LEVEL', default='INFO')

    # Convert string log level to logging constant
    numeric_level = getattr(logging, log_level.upper(), logging.INFO)

    # Base configuration
    log_config = {
        'version': 1,
        'disable_existing_loggers': False,
        'formatters': {
            'detailed': {
                'format': '%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s'
            },
            'simple': {
                'format': '%(asctime)s - %(levelname)s - %(message)s'
            }
        },
        'handlers': {
            'console': {
                'class': 'logging.StreamHandler',
                'level': numeric_level,
                'formatter': 'detailed' if environment == 'development' else 'simple'
            },
            'file': {
                'class': 'logging.FileHandler',
                'filename': 'app_data/app.log',
                'mode': 'a',
                'formatter': 'detailed'
            }
        },
        'loggers': {
            '': {  # Root logger
                'handlers': ['console', 'file'],
                'level': numeric_level,
                'propagate': True
            }
        }
    }

    # Ensure log directory exists
    os.makedirs('app_data', exist_ok=True)

    # Apply configuration
    logging.config.dictConfig(log_config)

    # Get logger
    logger = logging.getLogger(__name__)
    logger.info(f'Logging configured for {environment} environment at {log_level} level')
```

## app\utils\__init__.py

- Characters: 0
- Tokens: 0

```python

```

## Statistics

- Total Files: 16
- Total Characters: 34008
- Total Tokens: 7384
